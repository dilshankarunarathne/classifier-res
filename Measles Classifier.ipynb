{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from random import shuffle\n",
    "import random\n",
    "#for preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from random import shuffle\n",
    "#For augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#Transfer learning models\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras import Model, layers\n",
    "from numpy import loadtxt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# setting path of directory\n",
    "M_DIR =  \"/content/gdrive/My Drive/Colab Notebooks/Measles/\"\n",
    "O_DIR = \"/content/gdrive/My Drive/Colab Notebooks/Others/\"\n",
    "# storing all the files from directories M_DIR and O_DIR to Mimages and Oimages for accessing images directly\n",
    "Mimages = os.listdir(M_DIR)\n",
    "Oimages = os.listdir(O_DIR)\n",
    "sample_monkeypox = random.sample(Mimages,6)\n",
    "f,ax = plt.subplots(2,3,figsize=(15,9))\n",
    "for i in range(0,6):\n",
    "    im = cv2.imread(M_DIR +sample_monkeypox[i])\n",
    "    ax[i//3,i%3].imshow(im)\n",
    "    ax[i//3,i%3].axis('off')\n",
    "f.suptitle('Measles sample images',fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_others = random.sample(Oimages,6)\n",
    "f,ax = plt.subplots(2,3,figsize=(15,9))\n",
    "for i in range(0,6):\n",
    "    im = cv2.imread(O_DIR +sample_others[i])\n",
    "    ax[i//3,i%3].imshow(im)\n",
    "    ax[i//3,i%3].axis('off')\n",
    "f.suptitle('Others sample images',fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "for m in Mimages:\n",
    "    try:\n",
    "        image=cv2.imread(M_DIR+m)\n",
    "        image_from_array = PIL.Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "for o in Oimages:\n",
    "    try:\n",
    "        image=cv2.imread(O_DIR+o)\n",
    "        image_from_array = PIL.Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((224, 224))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#converting features and labels in array\n",
    "feats=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "# saving features and labels for later re-use\n",
    "np.save(\"/content/gdrive/My Drive/Colab Notebooks/me_feats_train\",feats)\n",
    "np.save(\"/content/gdrive/My Drive/Colab Notebooks/me_labels_train\",labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feats=np.load(\"/content/gdrive/My Drive/Colab Notebooks/me_feats_train.npy\")\n",
    "labels=np.load(\"/content/gdrive/My Drive/Colab Notebooks/me_labels_train.npy\")\n",
    "\n",
    "s=np.arange(feats.shape[0])\n",
    "np.random.shuffle(s)\n",
    "feats=feats[s]\n",
    "labels=labels[s]\n",
    "\n",
    "num_classes=len(np.unique(labels))\n",
    "len_data=len(feats)\n",
    "print(len_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# splitting cells images into 80:20 ratio i.e., 80% for training and 20% for testing purpose\n",
    "(x_train,x_test)=feats[(int)(0.2*len_data):],feats[:(int)(0.2*len_data)]\n",
    "\n",
    "(y_train,y_test)=labels[(int)(0.2*len_data):],labels[:(int)(0.2*len_data)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255 # As we are working on image data we are normalizing data by divinding 255.\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_len=len(x_train)\n",
    "test_len=len(x_test)\n",
    "\n",
    "\n",
    "#Doing One hot encoding as classifier has multiple classes\n",
    "y_train=to_categorical(y_train,num_classes)\n",
    "y_test=to_categorical(y_test,num_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "conv_base = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet')\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = conv_base.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(2, activation='softmax')(x)\n",
    "model = Model(conv_base.input, predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "#optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('.mdl_wts.hdf5', monitor='val_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2,\n",
    "                                   verbose=1, mode='min', min_lr=0.0000001)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [checkpoint,reduce_lr]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,batch_size=batch_size,callbacks=callbacks, validation_data=(x_test,y_test),epochs=epochs,verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MobileNet V2 Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(' MobileNet V2 Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# saving the weight of model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "model = load_model('.mdl_wts.hdf5')\n",
    "\n",
    "#checking the score of the model\n",
    "score=model.evaluate(x_test,y_test)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_val=np.load(\"/content/gdrive/My Drive/Colab Notebooks/me_feats_val.npy\")\n",
    "y_val=np.load(\"/content/gdrive/My Drive/Colab Notebooks/me_labels_val.npy\")\n",
    "\n",
    "s=np.arange(x_val.shape[0])\n",
    "np.random.shuffle(s)\n",
    "x_val=x_val[s]\n",
    "y_val=y_val[s]\n",
    "\n",
    "x_val = x_val.astype('float32')/255\n",
    "y_val=to_categorical(y_val,num_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking the accuracy of thr\n",
    "accuracy = model.evaluate(x_val, y_val, verbose=1)\n",
    "print('\\n', 'Validation_Accuracy:-', accuracy[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(x_val)\n",
    "pred = np.argmax(pred,axis = 1)\n",
    "y_true = np.argmax(y_val,axis = 1)\n",
    "\n",
    "#creating confusion matrix\n",
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "# plotting confusion matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('{}'.format(\n",
    "                           classification_report(y_true , pred)))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
